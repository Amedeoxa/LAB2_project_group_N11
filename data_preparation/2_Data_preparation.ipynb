{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Data preparation**"
      ],
      "metadata": {
        "id": "0nn4wZc5_0AI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generating non redundant datasets**"
      ],
      "metadata": {
        "id": "k9gHIEB3_ikk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FbfwUM9snZ1v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('uniq.pos.tsv', 'r') as clustered_pos, open('positive.tsv', 'r') as tot_pos, open('non_redundant_pos.tsv', 'w') as non_redundant_pos:\n",
        "  unique_ids = []\n",
        "  for name in clustered_pos:\n",
        "    name = name.rstrip()\n",
        "    unique_ids.append(name)\n",
        "  for line in tot_pos:\n",
        "    line = line.rstrip()\n",
        "    id = line.split('\\t')[0]\n",
        "    if id in unique_ids:\n",
        "      non_redundant_pos.write(line + '\\n')"
      ],
      "metadata": {
        "id": "WlVyNj5rnjAM"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('uniq.neg.tsv', 'r') as clustered_neg, open('negative.tsv', 'r') as neg_pos, open('non_redundant_neg.tsv', 'w') as non_redundant_neg:\n",
        "  unique_ids_neg = []\n",
        "  for name in clustered_neg:\n",
        "    name = name.rstrip()\n",
        "    unique_ids_neg.append(name)\n",
        "  for line in neg_pos:\n",
        "    line = line.rstrip()\n",
        "    id = line.split('\\t')[0]\n",
        "    if id in unique_ids_neg:\n",
        "      non_redundant_neg.write(line + '\\n')"
      ],
      "metadata": {
        "id": "aNHNeSIR9GO9"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "3CSqeFuqBOko"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_test_split(file):\n",
        "  with open(file, 'r') as dataset:\n",
        "    lines = [line.rstrip() for line in dataset]\n",
        "    random.seed(50)\n",
        "    random.shuffle(lines)\n",
        "    n = 80*len(lines)//100\n",
        "    training_set = lines[:n]\n",
        "    test_set = lines[n:]\n",
        "  return training_set, test_set\n",
        "\n",
        "with open('training_set.tsv', 'w') as training_set, open('test_set.tsv', 'w') as test_set:\n",
        "  training_set_p, test_set_p = training_test_split('non_redundant_pos.tsv')\n",
        "  training_set_n, test_set_n = training_test_split('non_redundant_neg.tsv')\n",
        "  training = training_set_p + training_set_n\n",
        "  test = test_set_p + test_set_n\n",
        "  for line in training:\n",
        "    training_set.write(line + '\\n')\n",
        "  for line in test:\n",
        "    test_set.write(line + '\\n')"
      ],
      "metadata": {
        "id": "9TgDZK0xBbJ1"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}